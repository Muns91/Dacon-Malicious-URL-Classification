{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7377cd-651c-48d2-bd00-577479bb94c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c7377cd-651c-48d2-bd00-577479bb94c2",
    "outputId": "973d3d93-c399-4d81-aa69-d786e727d873",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install tld\n",
    "!pip install googlesearch-python\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install transformers\n",
    "!pip install imblearn\n",
    "!pip install lgbm\n",
    "!pip install aiohttp\n",
    "!pip install seaborn\n",
    "!pip install lightgbm\n",
    "!pip install numpy==1.24.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p8TCDIM8ipiI",
   "metadata": {
    "id": "p8TCDIM8ipiI"
   },
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781b4ee-c882-439a-bd31-2599e70235c1",
   "metadata": {
    "id": "e781b4ee-c882-439a-bd31-2599e70235c1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from urllib.parse import urlparse, unquote\n",
    "import string\n",
    "import hashlib\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "import logging\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import time\n",
    "from scipy.stats import entropy\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "# 로깅 비활성화\n",
    "logging.getLogger(\"whois\").setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EN1G4G7MiuGv",
   "metadata": {
    "id": "EN1G4G7MiuGv"
   },
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c776aae-256c-4649-ad8a-14acf0d1ef43",
   "metadata": {
    "id": "0c776aae-256c-4649-ad8a-14acf0d1ef43"
   },
   "outputs": [],
   "source": [
    "# 학습/평가 데이터 로드\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# '[.]'을 '.'으로 복구\n",
    "train_df['URL'] = train_df['URL'].str.replace(r'\\[\\.\\]', '.', regex=True)\n",
    "test_df['URL'] = test_df['URL'].str.replace(r'\\[\\.\\]', '.', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8kT9FPObEQm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "d8kT9FPObEQm",
    "outputId": "1ae8ab07-4a88-4244-e6d0-b03c95597e8c"
   },
   "outputs": [],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cjYCEE0hjOMz",
   "metadata": {
    "id": "cjYCEE0hjOMz"
   },
   "outputs": [],
   "source": [
    "def extract_prime_url(url):\n",
    "    if '/' in url:\n",
    "        return url.split('/', 1)[0]  # 첫 번째 슬래시 왼쪽 부분\n",
    "    return url  # 슬래시가 없으면 전체 URL 반환\n",
    "\n",
    "def extract_other_domain(url):\n",
    "    if '/' in url:\n",
    "        return url.split('/', 1)[1]  # 첫 번째 슬래시 오른쪽 부분\n",
    "    return None\n",
    "\n",
    "\n",
    "# 새로운 컬럼 추가\n",
    "train_df['Prime_url'] = train_df['URL'].apply(extract_prime_url)\n",
    "test_df['Prime_url'] = test_df['URL'].apply(extract_prime_url)\n",
    "\n",
    "train_df['Other_domain'] = train_df['URL'].apply(extract_other_domain)\n",
    "test_df['Other_domain'] = test_df['URL'].apply(extract_other_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hx5sW-5NinnK",
   "metadata": {
    "id": "Hx5sW-5NinnK"
   },
   "source": [
    "# 길이 기반 특징 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8RbVL_4sjM9x",
   "metadata": {
    "id": "8RbVL_4sjM9x"
   },
   "outputs": [],
   "source": [
    "# # URL 길이\n",
    "train_df['length'] = train_df['URL'].str.len()\n",
    "test_df['length'] = test_df['URL'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QbeiSAsujM7j",
   "metadata": {
    "id": "QbeiSAsujM7j"
   },
   "outputs": [],
   "source": [
    "# 최대값과 최소값 구하기\n",
    "max_length = test_df['length'].max()\n",
    "min_length = test_df['length'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ezh8LE3ejM49",
   "metadata": {
    "id": "ezh8LE3ejM49"
   },
   "outputs": [],
   "source": [
    "# 최대 연속 소문자 길이 계산\n",
    "train_df['max_lowercase_sequence'] = train_df['URL'].apply(lambda x: max([len(seq) for seq in re.findall(r'[a-z]+', x)] or [0]))\n",
    "test_df['max_lowercase_sequence'] = test_df['URL'].apply(lambda x: max([len(seq) for seq in re.findall(r'[a-z]+', x)] or [0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mIfd6nS0jM2g",
   "metadata": {
    "id": "mIfd6nS0jM2g"
   },
   "outputs": [],
   "source": [
    "train_df['max_numeric_sequence'] = train_df['URL'].apply(lambda x: max([len(seq) for seq in re.findall(r'\\d+', x)] or [0]))\n",
    "test_df['max_numeric_sequence'] = test_df['URL'].apply(lambda x: max([len(seq) for seq in re.findall(r'\\d+', x)] or [0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_xOPhA2ojM0L",
   "metadata": {
    "id": "_xOPhA2ojM0L"
   },
   "outputs": [],
   "source": [
    "# 최대 연속 대문자 길이 계산\n",
    "train_df['max_uppercase_sequence'] = train_df['URL'].apply(lambda x: max([len(seq) for seq in re.findall(r'[A-Z]+', x)] or [0]))\n",
    "test_df['max_uppercase_sequence'] = test_df['URL'].apply(lambda x: max([len(seq) for seq in re.findall(r'[A-Z]+', x)] or [0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7nSAQgSLjhrW",
   "metadata": {
    "id": "7nSAQgSLjhrW"
   },
   "outputs": [],
   "source": [
    "# 첫 번째 / 이후의 호스트 길이 계산하는 컬럼 추가\n",
    "def host_length_after_slash(url):\n",
    "    if '/' in url:\n",
    "        # 첫 번째 / 이후의 부분 추출\n",
    "        host_part = url.split('/', 1)[1]  # 첫 번째 슬래시 이후의 부분\n",
    "        return len(host_part.split('/')[0])  # 호스트 길이 계산\n",
    "    return 0  # 슬래시가 없으면 0 반환\n",
    "\n",
    "train_df['Host Length After Slash'] = train_df['URL'].apply(host_length_after_slash)\n",
    "test_df['Host Length After Slash'] = test_df['URL'].apply(host_length_after_slash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vbE7X-VojhgP",
   "metadata": {
    "id": "vbE7X-VojhgP"
   },
   "outputs": [],
   "source": [
    "# 첫 번째 / 이전의 호스트 길이 계산하는 컬럼 추가\n",
    "def host_length_before_slash(url):\n",
    "    if '/' in url:\n",
    "        # 첫 번째 / 이전의 부분 추출\n",
    "        host_part = url.split('/', 1)[0]  # 첫 번째 슬래시 이전의 부분\n",
    "        return len(host_part)  # 호스트 길이 계산\n",
    "    return len(url)  # 슬래시가 없으면 전체 URL 길이를 반환\n",
    "\n",
    "train_df['Host Length Before Slash'] = train_df['URL'].apply(host_length_before_slash)\n",
    "test_df['Host Length Before Slash'] = test_df['URL'].apply(host_length_before_slash)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Uaf8BKBbi3NU",
   "metadata": {
    "id": "Uaf8BKBbi3NU"
   },
   "source": [
    "# 존재 여부 특징 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wRO3cRpxjWQa",
   "metadata": {
    "id": "wRO3cRpxjWQa"
   },
   "outputs": [],
   "source": [
    "# 단어 목록\n",
    "keywords = [\n",
    "    \"login\", \"bank\", \"secure\", \"update\", \"verify\",\n",
    "    \"account\", \"password\", \"security\", \"transaction\",\n",
    "    \"sensitive\", \"confidential\", \"payment\", \"access\",\n",
    "    \"protect\", \"fraud\", \"alert\", \"notify\", \"register\", \"dashboard\", \"profile\", \"checkout\", \"cart\", \"search\", \"terms\", \"privacy\"\n",
    "]\n",
    "# 각 URL에서 단어 포함 개수를 카운트하여 하나의 컬럼에 합산\n",
    "def count_keywords(url):\n",
    "    return sum(url.count(keyword) for keyword in keywords)\n",
    "\n",
    "# 모든 URL을 소문자로 변환하여 카운트\n",
    "train_df['keyword_count'] = train_df['URL'].apply(lambda x: count_keywords(x.lower()))\n",
    "test_df['keyword_count'] = test_df['URL'].apply(lambda x: count_keywords(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tmkh6ttXjWN9",
   "metadata": {
    "id": "tmkh6ttXjWN9"
   },
   "outputs": [],
   "source": [
    "# 단축 URL 서비스 확인 함수\n",
    "def shortening_service(url):\n",
    "    match = re.search(r'bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
    "                      r'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
    "                      r'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
    "                      r'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
    "                      r'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
    "                      r'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
    "                      r'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n",
    "                      r'tr\\.im|link\\.zip\\.net', url)\n",
    "    if match:\n",
    "        return 1  # 단축 URL 서비스가 발견됨\n",
    "    else:\n",
    "        return 0  # 단축 URL 서비스가 없음\n",
    "\n",
    "# 새로운 컬럼에 단축 URL 여부 추가\n",
    "train_df['short_url'] = train_df['URL'].apply(shortening_service)\n",
    "test_df['short_url'] = test_df['URL'].apply(shortening_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-W5yS8lejWLo",
   "metadata": {
    "id": "-W5yS8lejWLo"
   },
   "outputs": [],
   "source": [
    "# 체크할 파일 확장자 목록\n",
    "extensions = [\n",
    "    \".jpg\", \".jpeg\", \".png\", \".gif\", \".bmp\",  # 이미지\n",
    "    \".pdf\", \".doc\", \".docx\", \".xls\", \".xlsx\",  # 문서\n",
    "    \".mp4\", \".avi\", \".mov\",  # 비디오\n",
    "    \".mp3\", \".wav\",  # 오디오\n",
    "    \".zip\", \".rar\",  # 압축 파일\n",
    "    \".tiff\", \".tif\",  # 이미지\n",
    "    \".webp\",  # 이미지\n",
    "    \".svg\",  # 이미지\n",
    "    \".ppt\", \".pptx\",  # 문서\n",
    "    \".txt\",  # 문서\n",
    "    \".csv\",  # 문서\n",
    "    \".xml\",  # 문서\n",
    "    \".html\", \".htm\",  \".hwpx\"# 문서\n",
    "    \".mkv\",  # 비디오\n",
    "    \".wmv\",  # 비디오\n",
    "    \".flv\",  # 비디오\n",
    "    \".mpeg\", \".mpg\",  # 비디오\n",
    "    \".aac\",  # 오디오\n",
    "    \".flac\",  # 오디오\n",
    "    \".ogg\",  # 오디오\n",
    "    \".7z\",  # 압축 파일\n",
    "    \".tar\",  # 압축 파일\n",
    "    \".gz\",  # 압축 파일\n",
    "    \".bz2\",  # 압축 파일\n",
    "    \".iso\",  # 기타\n",
    "    \".json\",  # 기타\n",
    "    \".md\",  # 기타\n",
    "    \".psd\",  # 기타\n",
    "    \".ai\" , # 기타\n",
    "    \".lnk\", \".vbs\"\n",
    "]\n",
    "\n",
    "\n",
    "# 파일 확장자 존재 여부 확인 함수 정의\n",
    "def check_extensions(url):\n",
    "    return any(url.lower().endswith(ext) for ext in extensions)\n",
    "\n",
    "# 새로운 컬럼 추가: has_extension\n",
    "train_df['has_extension'] = train_df['URL'].apply(check_extensions)\n",
    "test_df['has_extension'] = test_df['URL'].apply(check_extensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "op1PthAZkIwF",
   "metadata": {
    "id": "op1PthAZkIwF"
   },
   "outputs": [],
   "source": [
    "# 체크할 특수 문자 리스트\n",
    "special_characters = ['-', '=']\n",
    "\n",
    "# 각 특수 문자의 개수를 카운트하는 label 생성\n",
    "for char in special_characters:\n",
    "    train_df[f'count_{char}'] = train_df['URL'].apply(lambda x: x.count(char))\n",
    "    test_df[f'count_{char}'] = test_df['URL'].apply(lambda x: x.count(char))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jQnc2YVJi3I_",
   "metadata": {
    "id": "jQnc2YVJi3I_"
   },
   "source": [
    "# 개수 기반 특징 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NWkJT_1ajVvS",
   "metadata": {
    "id": "NWkJT_1ajVvS"
   },
   "outputs": [],
   "source": [
    "train_df['path_depth'] = train_df['URL'].str.count('/')\n",
    "test_df['path_depth'] = test_df['URL'].str.count('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rORpYL-3jVr9",
   "metadata": {
    "id": "rORpYL-3jVr9"
   },
   "outputs": [],
   "source": [
    "# 서브도메인 개수\n",
    "train_df['subdomain_count'] = train_df['URL'].str.split('.').apply(lambda x: len(x) - 2)\n",
    "test_df['subdomain_count'] = test_df['URL'].str.split('.').apply(lambda x: len(x) - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AxWiQEI4jVpp",
   "metadata": {
    "id": "AxWiQEI4jVpp"
   },
   "outputs": [],
   "source": [
    "# URL에서 'www'의 개수 세기\n",
    "train_df['count-www'] = train_df['URL'].apply(lambda url: url.count('www'))\n",
    "test_df['count-www'] = test_df['URL'].apply(lambda url: url.count('www'))\n",
    "\n",
    "# mail\n",
    "train_df['count-mail'] = train_df['URL'].str.count('mail')\n",
    "test_df['count-mail'] = test_df['URL'].str.count('mail')\n",
    "\n",
    "# blog\n",
    "train_df['count-blog'] = train_df['URL'].str.count('blog')\n",
    "test_df['count-blog'] = test_df['URL'].str.count('blog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bwj_UQl4jnGe",
   "metadata": {
    "id": "Bwj_UQl4jnGe"
   },
   "outputs": [],
   "source": [
    "# 숫자의 개수\n",
    "train_df['digit_count'] = train_df['URL'].str.count(r'\\d')\n",
    "test_df['digit_count'] = test_df['URL'].str.count(r'\\d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lv4AJxUpjnDr",
   "metadata": {
    "id": "lv4AJxUpjnDr"
   },
   "outputs": [],
   "source": [
    "# 소문자 비율 계산\n",
    "train_df['lowercase_count'] = train_df['URL'].str.count(r'[a-z]')\n",
    "test_df['lowercase_count'] = test_df['URL'].str.count(r'[a-z]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DWsYReLnjt90",
   "metadata": {
    "id": "DWsYReLnjt90"
   },
   "outputs": [],
   "source": [
    "# 대문자 비율 계산\n",
    "train_df['uppercase_count'] = train_df['URL'].str.count(r'[A-Z]')\n",
    "test_df['uppercase_count'] = test_df['URL'].str.count(r'[A-Z]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z_SYjkE0jt7Y",
   "metadata": {
    "id": "z_SYjkE0jt7Y"
   },
   "outputs": [],
   "source": [
    "# 문자, 숫자, 특수 문자의 개수를 세는 함수\n",
    "def count_characters(url):\n",
    "    letters_count = sum(c.isalpha() for c in url)  # 문자 수\n",
    "    digits_count = sum(c.isdigit() for c in url)   # 숫자 수\n",
    "    special_chars_count = sum(c in string.punctuation for c in url)  # 특수 문자 수\n",
    "\n",
    "    return letters_count, digits_count, special_chars_count\n",
    "\n",
    "# train_df와 test_df에 대해 개수 계산 후 새로운 컬럼에 저장\n",
    "train_df['letters_count'], train_df['digits_count'], train_df['special_chars_count'] = zip(*train_df['Prime_url'].apply(count_characters))\n",
    "test_df['letters_count'], test_df['digits_count'], test_df['special_chars_count'] = zip(*test_df['Prime_url'].apply(count_characters))\n",
    "\n",
    "# 문자, 숫자, 특수 문자의 개수를 세는 함수\n",
    "def count_characters(text):\n",
    "    if text is None:  # None인 경우\n",
    "        return 0, 0, 0  # 모두 0 반환\n",
    "    letters_count = sum(c.isalpha() for c in text)  # 문자 수\n",
    "    digits_count = sum(c.isdigit() for c in text)   # 숫자 수\n",
    "    special_chars_count = sum(c in string.punctuation for c in text)  # 특수 문자 수\n",
    "\n",
    "    return letters_count, digits_count, special_chars_count\n",
    "\n",
    "# train_df와 test_df에 대해 Other_domain에 대한 개수 계산 후 새로운 컬럼에 저장\n",
    "train_df['letters_count_other'], train_df['digits_count_other'], train_df['special_chars_count_other'] = zip(*train_df['Other_domain'].apply(count_characters))\n",
    "test_df['letters_count_other'], test_df['digits_count_other'], test_df['special_chars_count_other'] = zip(*test_df['Other_domain'].apply(count_characters))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "K4B85ZmGj5gm",
   "metadata": {
    "id": "K4B85ZmGj5gm"
   },
   "outputs": [],
   "source": [
    "# 문자를 제거한 나머지의 개수를 계산하는 함수\n",
    "def non_alpha_count(url):\n",
    "    non_alpha = re.sub(r'[a-zA-Z]', '', url)  # 문자(알파벳)만 제거\n",
    "    return len(non_alpha) if non_alpha else 0\n",
    "\n",
    "train_df['Non Alpha Count'] = train_df['URL'].apply(non_alpha_count)\n",
    "test_df['Non Alpha Count'] = test_df['URL'].apply(non_alpha_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MnbKJv6di3F7",
   "metadata": {
    "id": "MnbKJv6di3F7"
   },
   "source": [
    "# 기타 기반 특징 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fZH0O-T6jU3H",
   "metadata": {
    "id": "fZH0O-T6jU3H"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 주어진 get_url_region 함수\n",
    "def get_url_region(primary_domain):\n",
    "    ccTLD_to_region =  {\n",
    "\".ac\": \"Ascension Island\",\n",
    "\".ad\": \"Andorra\",\n",
    "\".ae\": \"United Arab Emirates\",\n",
    "\".af\": \"Afghanistan\",\n",
    "\".ag\": \"Antigua and Barbuda\",\n",
    "\".ai\": \"Anguilla\",\n",
    "\".al\": \"Albania\",\n",
    "\".am\": \"Armenia\",\n",
    "\".an\": \"Netherlands Antilles\",\n",
    "\".ao\": \"Angola\",\n",
    "\".aq\": \"Antarctica\",\n",
    "\".ar\": \"Argentina\",\n",
    "\".as\": \"American Samoa\",\n",
    "\".at\": \"Austria\",\n",
    "\".au\": \"Australia\",\n",
    "\".aw\": \"Aruba\",\n",
    "\".ax\": \"Åland Islands\",\n",
    "\".az\": \"Azerbaijan\",\n",
    "\".ba\": \"Bosnia and Herzegovina\",\n",
    "\".bb\": \"Barbados\",\n",
    "\".bd\": \"Bangladesh\",\n",
    "\".be\": \"Belgium\",\n",
    "\".bf\": \"Burkina Faso\",\n",
    "\".bg\": \"Bulgaria\",\n",
    "\".bh\": \"Bahrain\",\n",
    "\".bi\": \"Burundi\",\n",
    "\".bj\": \"Benin\",\n",
    "\".bm\": \"Bermuda\",\n",
    "\".bn\": \"Brunei Darussalam\",\n",
    "\".bo\": \"Bolivia\",\n",
    "\".br\": \"Brazil\",\n",
    "\".bs\": \"Bahamas\",\n",
    "\".bt\": \"Bhutan\",\n",
    "\".bv\": \"Bouvet Island\",\n",
    "\".bw\": \"Botswana\",\n",
    "\".by\": \"Belarus\",\n",
    "\".bz\": \"Belize\",\n",
    "\".ca\": \"Canada\",\n",
    "\".cc\": \"Cocos Islands\",\n",
    "\".cd\": \"Democratic Republic of the Congo\",\n",
    "\".cf\": \"Central African Republic\",\n",
    "\".cg\": \"Republic of the Congo\",\n",
    "\".ch\": \"Switzerland\",\n",
    "\".ci\": \"Côte d'Ivoire\",\n",
    "\".ck\": \"Cook Islands\",\n",
    "\".cl\": \"Chile\",\n",
    "\".cm\": \"Cameroon\",\n",
    "\".cn\": \"China\",\n",
    "\".co\": \"Colombia\",\n",
    "\".cr\": \"Costa Rica\",\n",
    "\".cu\": \"Cuba\",\n",
    "\".cv\": \"Cape Verde\",\n",
    "\".cw\": \"Curaçao\",\n",
    "\".cx\": \"Christmas Island\",\n",
    "\".cy\": \"Cyprus\",\n",
    "\".cz\": \"Czech Republic\",\n",
    "\".de\": \"Germany\",\n",
    "\".dj\": \"Djibouti\",\n",
    "\".dk\": \"Denmark\",\n",
    "\".dm\": \"Dominica\",\n",
    "\".do\": \"Dominican Republic\",\n",
    "\".dz\": \"Algeria\",\n",
    "\".ec\": \"Ecuador\",\n",
    "\".ee\": \"Estonia\",\n",
    "\".eg\": \"Egypt\",\n",
    "\".er\": \"Eritrea\",\n",
    "\".es\": \"Spain\",\n",
    "\".et\": \"Ethiopia\",\n",
    "\".eu\": \"European Union\",\n",
    "\".fi\": \"Finland\",\n",
    "\".fj\": \"Fiji\",\n",
    "\".fk\": \"Falkland Islands\",\n",
    "\".fm\": \"Federated States of Micronesia\",\n",
    "\".fo\": \"Faroe Islands\",\n",
    "\".fr\": \"France\",\n",
    "\".ga\": \"Gabon\",\n",
    "\".gb\": \"United Kingdom\",\n",
    "\".gd\": \"Grenada\",\n",
    "\".ge\": \"Georgia\",\n",
    "\".gf\": \"French Guiana\",\n",
    "\".gg\": \"Guernsey\",\n",
    "\".gh\": \"Ghana\",\n",
    "\".gi\": \"Gibraltar\",\n",
    "\".gl\": \"Greenland\",\n",
    "\".gm\": \"Gambia\",\n",
    "\".gn\": \"Guinea\",\n",
    "\".gp\": \"Guadeloupe\",\n",
    "\".gq\": \"Equatorial Guinea\",\n",
    "\".gr\": \"Greece\",\n",
    "\".gs\": \"South Georgia and the South Sandwich Islands\",\n",
    "\".gt\": \"Guatemala\",\n",
    "\".gu\": \"Guam\",\n",
    "\".gw\": \"Guinea-Bissau\",\n",
    "\".gy\": \"Guyana\",\n",
    "\".hk\": \"Hong Kong\",\n",
    "\".hm\": \"Heard Island and McDonald Islands\",\n",
    "\".hn\": \"Honduras\",\n",
    "\".hr\": \"Croatia\",\n",
    "\".ht\": \"Haiti\",\n",
    "\".hu\": \"Hungary\",\n",
    "\".id\": \"Indonesia\",\n",
    "\".ie\": \"Ireland\",\n",
    "\".il\": \"Israel\",\n",
    "\".im\": \"Isle of Man\",\n",
    "\".in\": \"India\",\n",
    "\".io\": \"British Indian Ocean Territory\",\n",
    "\".iq\": \"Iraq\",\n",
    "\".ir\": \"Iran\",\n",
    "\".is\": \"Iceland\",\n",
    "\".it\": \"Italy\",\n",
    "\".je\": \"Jersey\",\n",
    "\".jm\": \"Jamaica\",\n",
    "\".jo\": \"Jordan\",\n",
    "\".jp\": \"Japan\",\n",
    "\".ke\": \"Kenya\",\n",
    "\".kg\": \"Kyrgyzstan\",\n",
    "\".kh\": \"Cambodia\",\n",
    "\".ki\": \"Kiribati\",\n",
    "\".km\": \"Comoros\",\n",
    "\".kn\": \"Saint Kitts and Nevis\",\n",
    "\".kp\": \"Democratic People's Republic of Korea (North Korea)\",\n",
    "\".kr\": \"Republic of Korea (South Korea)\",\n",
    "\".kw\": \"Kuwait\",\n",
    "\".ky\": \"Cayman Islands\",\n",
    "\".kz\": \"Kazakhstan\",\n",
    "\".la\": \"Laos\",\n",
    "\".lb\": \"Lebanon\",\n",
    "\".lc\": \"Saint Lucia\",\n",
    "\".li\": \"Liechtenstein\",\n",
    "\".lk\": \"Sri Lanka\",\n",
    "\".lr\": \"Liberia\",\n",
    "\".ls\": \"Lesotho\",\n",
    "\".lt\": \"Lithuania\",\n",
    "\".lu\": \"Luxembourg\",\n",
    "\".lv\": \"Latvia\",\n",
    "\".ly\": \"Libya\",\n",
    "\".ma\": \"Morocco\",\n",
    "\".mc\": \"Monaco\",\n",
    "\".md\": \"Moldova\",\n",
    "\".me\": \"Montenegro\",\n",
    "\".mf\": \"Saint Martin (French part)\",\n",
    "\".mg\": \"Madagascar\",\n",
    "\".mh\": \"Marshall Islands\",\n",
    "\".mk\": \"North Macedonia\",\n",
    "\".ml\": \"Mali\",\n",
    "\".mm\": \"Myanmar\",\n",
    "\".mn\": \"Mongolia\",\n",
    "\".mo\": \"Macao\",\n",
    "\".mp\": \"Northern Mariana Islands\",\n",
    "\".mq\": \"Martinique\",\n",
    "\".mr\": \"Mauritania\",\n",
    "\".ms\": \"Montserrat\",\n",
    "\".mt\": \"Malta\",\n",
    "\".mu\": \"Mauritius\",\n",
    "\".mv\": \"Maldives\",\n",
    "\".mw\": \"Malawi\",\n",
    "\".mx\": \"Mexico\",\n",
    "\".my\": \"Malaysia\",\n",
    "\".mz\": \"Mozambique\",\n",
    "\".na\": \"Namibia\",\n",
    "\".nc\": \"New Caledonia\",\n",
    "\".ne\": \"Niger\",\n",
    "\".nf\": \"Norfolk Island\",\n",
    "\".ng\": \"Nigeria\",\n",
    "\".ni\": \"Nicaragua\",\n",
    "\".nl\": \"Netherlands\",\n",
    "\".no\": \"Norway\",\n",
    "\".np\": \"Nepal\",\n",
    "\".nr\": \"Nauru\",\n",
    "\".nu\": \"Niue\",\n",
    "\".nz\": \"New Zealand\",\n",
    "\".om\": \"Oman\",\n",
    "\".pa\": \"Panama\",\n",
    "\".pe\": \"Peru\",\n",
    "\".pf\": \"French Polynesia\",\n",
    "\".pg\": \"Papua New Guinea\",\n",
    "\".ph\": \"Philippines\",\n",
    "\".pk\": \"Pakistan\",\n",
    "\".pl\": \"Poland\",\n",
    "\".pm\": \"Saint Pierre and Miquelon\",\n",
    "\".pn\": \"Pitcairn\",\n",
    "\".pr\": \"Puerto Rico\",\n",
    "\".ps\": \"Palestinian Territory\",\n",
    "\".pt\": \"Portugal\",\n",
    "\".pw\": \"Palau\",\n",
    "\".py\": \"Paraguay\",\n",
    "\".qa\": \"Qatar\",\n",
    "\".re\": \"Réunion\",\n",
    "\".ro\": \"Romania\",\n",
    "\".rs\": \"Serbia\",\n",
    "\".ru\": \"Russia\",\n",
    "\".rw\": \"Rwanda\",\n",
    "\".sa\": \"Saudi Arabia\",\n",
    "\".sb\": \"Solomon Islands\",\n",
    "\".sc\": \"Seychelles\",\n",
    "\".sd\": \"Sudan\",\n",
    "\".se\": \"Sweden\",\n",
    "\".sg\": \"Singapore\",\n",
    "\".sh\": \"Saint Helena\",\n",
    "\".si\": \"Slovenia\",\n",
    "\".sj\": \"Svalbard and Jan Mayen\",\n",
    "\".sk\": \"Slovakia\",\n",
    "\".sl\": \"Sierra Leone\",\n",
    "\".sm\": \"San Marino\",\n",
    "\".sn\": \"Senegal\",\n",
    "\".so\": \"Somalia\",\n",
    "\".sr\": \"Suriname\",\n",
    "\".ss\": \"South Sudan\",\n",
    "\".st\": \"São Tomé and Príncipe\",\n",
    "\".sv\": \"El Salvador\",\n",
    "\".sx\": \"Sint Maarten (Dutch part)\",\n",
    "\".sy\": \"Syria\",\n",
    "\".sz\": \"Eswatini\",\n",
    "\".tc\": \"Turks and Caicos Islands\",\n",
    "\".td\": \"Chad\",\n",
    "\".tf\": \"French Southern Territories\",\n",
    "\".tg\": \"Togo\",\n",
    "\".th\": \"Thailand\",\n",
    "\".tj\": \"Tajikistan\",\n",
    "\".tk\": \"Tokelau\",\n",
    "\".tl\": \"Timor-Leste\",\n",
    "\".tm\": \"Turkmenistan\",\n",
    "\".tn\": \"Tunisia\",\n",
    "\".to\": \"Tonga\",\n",
    "\".tr\": \"Turkey\",\n",
    "\".tt\": \"Trinidad and Tobago\",\n",
    "\".tv\": \"Tuvalu\",\n",
    "\".tw\": \"Taiwan\",\n",
    "\".tz\": \"Tanzania\",\n",
    "\".ua\": \"Ukraine\",\n",
    "\".ug\": \"Uganda\",\n",
    "\".uk\": \"United Kingdom\",\n",
    "\".us\": \"United States\",\n",
    "\".uy\": \"Uruguay\",\n",
    "\".uz\": \"Uzbekistan\",\n",
    "\".va\": \"Vatican City\",\n",
    "\".vc\": \"Saint Vincent and the Grenadines\",\n",
    "\".ve\": \"Venezuela\",\n",
    "\".vg\": \"British Virgin Islands\",\n",
    "\".vi\": \"U.S. Virgin Islands\",\n",
    "\".vn\": \"Vietnam\",\n",
    "\".vu\": \"Vanuatu\",\n",
    "\".wf\": \"Wallis and Futuna\",\n",
    "\".ws\": \"Samoa\",\n",
    "\".ye\": \"Yemen\",\n",
    "\".yt\": \"Mayotte\",\n",
    "\".za\": \"South Africa\",\n",
    "\".zm\": \"Zambia\",\n",
    "\".zw\": \"Zimbabwe\"\n",
    "}\n",
    "\n",
    "    for ccTLD in ccTLD_to_region:\n",
    "        if primary_domain.endswith(ccTLD):\n",
    "            return ccTLD_to_region[ccTLD]\n",
    "\n",
    "    return \"ETC\"\n",
    "\n",
    "# Prime_url에서 최상위 도메인 추출하는 함수\n",
    "def extract_top_level_domain(prime_url):\n",
    "    # '.'로 나누어 마지막 부분을 가져옴\n",
    "    domain_parts = prime_url.split('.')\n",
    "    return '.' + domain_parts[-1]  # 최상위 도메인\n",
    "\n",
    "# Prime_url에서 최상위 도메인 추출 후 지역 찾기\n",
    "train_df['Top Level Domain'] = train_df['Prime_url'].apply(extract_top_level_domain)\n",
    "train_df['Region'] = train_df['Top Level Domain'].apply(get_url_region)\n",
    "\n",
    "test_df['Top Level Domain'] = test_df['Prime_url'].apply(extract_top_level_domain)\n",
    "test_df['Region'] = test_df['Top Level Domain'].apply(get_url_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pTzq6u0MjUz9",
   "metadata": {
    "id": "pTzq6u0MjUz9"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# LabelEncoder 객체 생성\n",
    "label_encoder = LabelEncoder()\n",
    "# Region 컬럼을 레이블 인코딩 (학습 데이터)\n",
    "train_df['Region_Encoded'] = label_encoder.fit_transform(train_df['Region'])\n",
    "# 테스트 데이터에 레이블 인코딩 적용 (학습 데이터에서 사용한 인코더 재사용)\n",
    "test_df['Region_Encoded'] = label_encoder.transform(test_df['Region'])\n",
    "# 인코딩된 레이블과 원래 레이블 간의 매핑 확인\n",
    "label_mapping = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab97243-2c62-4e43-b254-7fd194734d80",
   "metadata": {
    "id": "3ab97243-2c62-4e43-b254-7fd194734d80"
   },
   "outputs": [],
   "source": [
    "def hash_url(url):\n",
    "    if url is None:\n",
    "        return 0  # None인 경우 0 반환\n",
    "    return int(hashlib.sha256(url.encode()).hexdigest(), 16)  # 해시값 생성\n",
    "\n",
    "# Prime_url 컬럼과 Other_domain 컬럼을 해싱하여 새로운 컬럼 생성\n",
    "train_df['Prime_url_hashed'] = train_df['Prime_url'].apply(hash_url)\n",
    "train_df['Other_domain_hashed'] = train_df['Other_domain'].apply(hash_url)\n",
    "\n",
    "test_df['Prime_url_hashed'] = test_df['Prime_url'].apply(hash_url)\n",
    "test_df['Other_domain_hashed'] = test_df['Other_domain'].apply(hash_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7058f87-ff5b-449d-a262-dc1ac9963cac",
   "metadata": {
    "id": "e7058f87-ff5b-449d-a262-dc1ac9963cac"
   },
   "outputs": [],
   "source": [
    "def url_to_number(url):\n",
    "    return int(''.join(str(ord(c)) for c in url))% (10 ** 10)\n",
    "\n",
    "# Prime_url 컬럼을 숫자로 변환\n",
    "train_df['Prime_url_encoded'] = train_df['Prime_url'].apply(url_to_number)\n",
    "test_df['Prime_url_encoded'] = test_df['Prime_url'].apply(url_to_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca48933-c13d-4e4e-8da9-38eead48193f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08620ab5-45c5-488e-b6f3-48097d1aa692",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y numpy\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gM1vGKo5kf2V",
   "metadata": {
    "id": "gM1vGKo5kf2V"
   },
   "source": [
    "# BERT Based URL Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb97e0-6726-45a3-8831-d240d55e9738",
   "metadata": {
    "id": "c8cb97e0-6726-45a3-8831-d240d55e9738",
    "outputId": "8f87d50a-e9e1-4efe-d015-9a7854b2ac70"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm  # tqdm 라이브러리 임포트\n",
    "\n",
    "# GPU가 사용 가능한지 확인하고 모델을 GPU로 이동\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# BERT 모델과 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "# train_df의 URL 임베딩 생성 (진행율 표시)\n",
    "url_embeddings_train = []\n",
    "for url in tqdm(train_df['URL'], desc=\"Processing train URLs\"):\n",
    "    tokens = tokenizer.encode(url, add_special_tokens=True, max_length=512, truncation=True, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # 결과를 CPU로 이동\n",
    "    url_embeddings_train.append(embeddings)\n",
    "\n",
    "url_embeddings_train = torch.tensor(url_embeddings_train)\n",
    "\n",
    "# test_df의 URL 임베딩 생성 (진행율 표시)\n",
    "url_embeddings_test = []\n",
    "for url in tqdm(test_df['URL'], desc=\"Processing test URLs\"):\n",
    "    tokens = tokenizer.encode(url, add_special_tokens=True, max_length=512, truncation=True, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()  # 결과를 CPU로 이동\n",
    "    url_embeddings_test.append(embeddings)\n",
    "\n",
    "url_embeddings_test = torch.tensor(url_embeddings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d6a0c-a7a8-48a3-86c5-46bb38e28b88",
   "metadata": {
    "id": "126d6a0c-a7a8-48a3-86c5-46bb38e28b88"
   },
   "outputs": [],
   "source": [
    "# X와 y 재정의\n",
    "X = train_df.drop(columns=['ID', 'label', 'URL', 'Prime_url','Other_domain','Top Level Domain', 'Region'])\n",
    "y = train_df['label']\n",
    "\n",
    "# 테스트 데이터 처리\n",
    "X_test = test_df.drop(columns=['ID', 'URL', 'Prime_url','Other_domain','Top Level Domain', 'Region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29aa5e-85a4-41da-bbd1-f13c894cfcee",
   "metadata": {
    "id": "5b29aa5e-85a4-41da-bbd1-f13c894cfcee"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "feature_cols = X.columns.tolist()  # X의 모든 컬럼을 feature_cols로 사용\n",
    "\n",
    "\n",
    "# 스케일러 초기화\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 학습 데이터 피처 스케일링 (원래 DataFrame 유지)\n",
    "train_df_scaled = X.copy()  # 기존 train_df 유지\n",
    "train_df_scaled[feature_cols] = scaler.fit_transform(X[feature_cols])\n",
    "\n",
    "# 테스트 데이터 피처 스케일링 (학습 데이터의 스케일러 사용)\n",
    "test_df_scaled = X_test.copy()  # 기존 test_df 유지\n",
    "test_df_scaled[feature_cols] = scaler.transform(X_test[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790f271-ad83-464e-907a-d5b1e1ffbf5d",
   "metadata": {
    "id": "4790f271-ad83-464e-907a-d5b1e1ffbf5d"
   },
   "outputs": [],
   "source": [
    "other_numeric_data_tensor = torch.tensor(train_df_scaled.values)\n",
    "concatenated_features = torch.cat((url_embeddings_train, other_numeric_data_tensor), dim=1)\n",
    "\n",
    "# PyTorch 텐서 변환 (테스트 데이터)\n",
    "other_numeric_data_test = torch.tensor(test_df_scaled.values, dtype=torch.float32)\n",
    "concatenated_features_test = torch.cat((url_embeddings_test, other_numeric_data_test), dim=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(concatenated_features, y, stratify = y, shuffle=True, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4321a1b-2082-4c91-969f-32f9fcb6356e",
   "metadata": {
    "id": "c4321a1b-2082-4c91-969f-32f9fcb6356e",
    "outputId": "d0598afe-d300-40c7-c9c1-a0b2e33c6adc"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db6258d-316d-4cb2-b793-4ca1108b84f6",
   "metadata": {
    "id": "8db6258d-316d-4cb2-b793-4ca1108b84f6",
    "outputId": "d1d1f256-98a2-495f-ef65-1b5d54da6be6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# LightGBM Classifier 초기화\n",
    "model_lgb = LGBMClassifier(\n",
    "    objective='binary',\n",
    "    metric='binary_logloss',\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=60,\n",
    "    n_estimators=5000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "model_lgb.fit(X_val, y_val)\n",
    "\n",
    "# 검증 데이터 예측 및 ROC-AUC 계산\n",
    "y_val_pred_prob = model_lgb.predict_proba(X_val)[:, 1]\n",
    "auc = roc_auc_score(y_val, y_val_pred_prob)\n",
    "\n",
    "print(f\"Validation ROC-AUC: {auc:.4f}\")\n",
    "\n",
    "# # Validation ROC-AUC: 0.9529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02700132-2cad-450d-9e98-9511ac64542e",
   "metadata": {
    "id": "02700132-2cad-450d-9e98-9511ac64542e",
    "outputId": "f30d90b1-ad8e-4bd5-a0c3-a2cd1bdc4e48"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "# 예측 클래스 생성 (0 또는 1)\n",
    "y_val_pred = model_lgb.predict(X_val)\n",
    "\n",
    "# 컨퓨전 매트릭스 계산\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "# 컨퓨전 매트릭스 시각화\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model_lgb.classes_)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748b968b-e3b6-4263-883e-475dc118efb6",
   "metadata": {
    "id": "748b968b-e3b6-4263-883e-475dc118efb6",
    "outputId": "d392121f-3daf-4061-d6dc-b584d5ed6267"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 평가 데이터 추론\n",
    "# 단일 모델의 예측 확률 계산\n",
    "test_probabilities = model_lgb.predict_proba(concatenated_features_test)[:, 1]  # 악성 URL(1)일 확률\n",
    "\n",
    "print('Inference Done.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c59bf1a-fa19-4aa5-9d20-b3df54d0f2ad",
   "metadata": {
    "id": "6c59bf1a-fa19-4aa5-9d20-b3df54d0f2ad",
    "outputId": "2697808a-8a48-498d-98f9-6f38a3bc8ea4"
   },
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "test_df['probability'] = test_probabilities\n",
    "test_df[['ID', 'probability']].to_csv('./submission_RUNPOD.csv', index=False)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4b1693-9ba3-4223-ba13-452cfbc46ab3",
   "metadata": {
    "id": "df4b1693-9ba3-4223-ba13-452cfbc46ab3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
